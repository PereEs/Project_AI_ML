{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c40ecc6",
   "metadata": {},
   "source": [
    "# Project 3 — Bias–Variance with Polynomial Regression\n",
    "\n",
    "This notebook explores bias–variance trade-offs by fitting polynomial regression models of increasing degree.\n",
    "\n",
    "## Objectives\n",
    "- Load the dataset from a URL (or local fallback).\n",
    "- Perform quick EDA and visualize the target.\n",
    "- Train polynomial models for degrees 1…15.\n",
    "- Compare Train/Validation/Test errors.\n",
    "- Optionally add **Ridge**/**Lasso** regularization.\n",
    "\n",
    "Dataset columns:\n",
    "- `x` — feature\n",
    "- `y` — target\n",
    "- `split` — one of `train`, `val`, `test`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a2f86",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e6cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from urllib.error import URLError\n",
    "import io, sys, os\n",
    "print('Versions ->', 'numpy', np.__version__, 'pandas', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6356db26",
   "metadata": {},
   "source": [
    "## 2) Load data (URL first, local fallback)\n",
    "Set `DATA_URL` to your **raw** CSV URL (GitHub/Drive), e.g.\n",
    "\n",
    "```\n",
    "DATA_URL = \"https://raw.githubusercontent.com/<user>/<repo>/main/project3_bias_variance_curve.csv\"\n",
    "```\n",
    "\n",
    "If the URL fails, it will try to read a local file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99b446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://raw.githubusercontent.com/PereEs/Project_AI_ML/main/project3_bias_variance_curve.csv\"  # <- change if needed\n",
    "LOCAL_PATH = \"project3_bias_variance_curve.csv\"  # fallback\n",
    "\n",
    "def load_dataset(url: str, local_path: str):\n",
    "    try:\n",
    "        df = pd.read_csv(url)\n",
    "        print('Loaded from URL:', url)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print('URL load failed:', e)\n",
    "        try:\n",
    "            df = pd.read_csv(local_path)\n",
    "            print('Loaded local file:', local_path)\n",
    "            return df\n",
    "        except Exception as e2:\n",
    "            print('Local load failed:', e2)\n",
    "            raise\n",
    "\n",
    "df = load_dataset(DATA_URL, LOCAL_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a0f9e",
   "metadata": {},
   "source": [
    "## 3) Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "display(df.describe(include='all'))\n",
    "print('\\nCounts by split:')\n",
    "print(df['split'].value_counts())\n",
    "\n",
    "# Scatter by split\n",
    "for sp in ['train','val','test']:\n",
    "    sub = df[df['split']==sp]\n",
    "    plt.figure()\n",
    "    plt.title(f'x vs y — {sp}')\n",
    "    plt.scatter(sub['x'], sub['y'])\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b02e6ac",
   "metadata": {},
   "source": [
    "## 4) Helpers — fit & evaluate across degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_poly_model(x, y, degree=1, reg=None, alpha=1.0):\n",
    "    steps = [('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "             ('scaler', StandardScaler())]\n",
    "    if reg is None:\n",
    "        steps.append(('lin', LinearRegression()))\n",
    "    elif reg == 'ridge':\n",
    "        steps.append(('ridge', Ridge(alpha=alpha, random_state=0)))\n",
    "    elif reg == 'lasso':\n",
    "        steps.append(('lasso', Lasso(alpha=alpha, random_state=0, max_iter=20000)))\n",
    "    else:\n",
    "        raise ValueError('reg must be None, \"ridge\", or \"lasso\"')\n",
    "    model = Pipeline(steps)\n",
    "    model.fit(x.reshape(-1,1), y)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "    yhat = model.predict(x.reshape(-1,1))\n",
    "    mse = mean_squared_error(y, yhat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y, yhat)\n",
    "    return {'mse': mse, 'rmse': rmse, 'r2': r2}\n",
    "\n",
    "def split_xy(df):\n",
    "    x_train = df[df.split=='train']['x'].values\n",
    "    y_train = df[df.split=='train']['y'].values\n",
    "    x_val   = df[df.split=='val']['x'].values\n",
    "    y_val   = df[df.split=='val']['y'].values\n",
    "    x_test  = df[df.split=='test']['x'].values\n",
    "    y_test  = df[df.split=='test']['y'].values\n",
    "    return (x_train,y_train,x_val,y_val,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e5c2e",
   "metadata": {},
   "source": [
    "## 5) Train degrees 1…15 (no regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = list(range(1,16))\n",
    "x_tr,y_tr,x_va,y_va,x_te,y_te = split_xy(df)\n",
    "\n",
    "results = []\n",
    "models = {}\n",
    "for d in degrees:\n",
    "    m = fit_poly_model(x_tr, y_tr, degree=d, reg=None)\n",
    "    models[d] = m\n",
    "    r_tr = evaluate_model(m, x_tr, y_tr)\n",
    "    r_va = evaluate_model(m, x_va, y_va)\n",
    "    r_te = evaluate_model(m, x_te, y_te)\n",
    "    results.append({'degree': d,\n",
    "                    'train_rmse': r_tr['rmse'], 'val_rmse': r_va['rmse'], 'test_rmse': r_te['rmse'],\n",
    "                    'train_r2': r_tr['r2'], 'val_r2': r_va['r2'], 'test_r2': r_te['r2']})\n",
    "res = pd.DataFrame(results)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e67abbe",
   "metadata": {},
   "source": [
    "## 6) Error vs degree plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad70839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE vs Degree\n",
    "plt.figure()\n",
    "plt.plot(res['degree'], res['train_rmse'], marker='o', label='Train')\n",
    "plt.plot(res['degree'], res['val_rmse'], marker='o', label='Validation')\n",
    "plt.plot(res['degree'], res['test_rmse'], marker='o', label='Test')\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE vs Degree (no regularization)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# R2 vs Degree\n",
    "plt.figure()\n",
    "plt.plot(res['degree'], res['train_r2'], marker='o', label='Train')\n",
    "plt.plot(res['degree'], res['val_r2'], marker='o', label='Validation')\n",
    "plt.plot(res['degree'], res['test_r2'], marker='o', label='Test')\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.title('R^2 vs Degree (no regularization)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2941cc",
   "metadata": {},
   "source": [
    "## 7) Best degree by validation RMSE & residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c378932",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = res.iloc[res['val_rmse'].idxmin()]\n",
    "best_degree = int(best_row['degree'])\n",
    "print('Best degree (by Val RMSE):', best_degree)\n",
    "best_model = models[best_degree]\n",
    "\n",
    "# Residuals on train and validation\n",
    "for split_name,(x,y) in {'train':(x_tr,y_tr), 'val':(x_va,y_va)}.items():\n",
    "    yhat = best_model.predict(x.reshape(-1,1))\n",
    "    resid = y - yhat\n",
    "    plt.figure()\n",
    "    plt.scatter(yhat, resid)\n",
    "    plt.axhline(0)\n",
    "    plt.xlabel('Predicted y')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'Residuals — {split_name} (degree={best_degree})')\n",
    "    plt.show()\n",
    "\n",
    "# Fit curve visualization\n",
    "x_grid = np.linspace(df['x'].min(), df['x'].max(), 400)\n",
    "y_grid = best_model.predict(x_grid.reshape(-1,1))\n",
    "plt.figure()\n",
    "plt.scatter(x_tr, y_tr, alpha=0.6, label='train')\n",
    "plt.scatter(x_va, y_va, alpha=0.6, label='val')\n",
    "plt.plot(x_grid, y_grid, linewidth=2, label=f'fit degree {best_degree}')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Best model fit'); plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c46b14",
   "metadata": {},
   "source": [
    "## 8) Regularization sweep (Ridge/Lasso) [optional]\n",
    "Try different `alpha` values to stabilize high-degree polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d1f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_regularization(kind='ridge', degree=12, alphas=(0.01,0.1,1,10,100)):\n",
    "    rows = []\n",
    "    for a in alphas:\n",
    "        m = fit_poly_model(x_tr, y_tr, degree=degree, reg=kind, alpha=a)\n",
    "        r_tr = evaluate_model(m, x_tr, y_tr)\n",
    "        r_va = evaluate_model(m, x_va, y_va)\n",
    "        r_te = evaluate_model(m, x_te, y_te)\n",
    "        rows.append({'alpha': a,\n",
    "                     'train_rmse': r_tr['rmse'], 'val_rmse': r_va['rmse'], 'test_rmse': r_te['rmse']})\n",
    "    out = pd.DataFrame(rows)\n",
    "    display(out)\n",
    "    plt.figure()\n",
    "    plt.plot(out['alpha'], out['train_rmse'], marker='o', label='Train')\n",
    "    plt.plot(out['alpha'], out['val_rmse'], marker='o', label='Validation')\n",
    "    plt.plot(out['alpha'], out['test_rmse'], marker='o', label='Test')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('alpha (log scale)'); plt.ylabel('RMSE')\n",
    "    plt.title(f'{kind.title()} regularization — degree {degree}')\n",
    "    plt.legend(); plt.show()\n",
    "    return out\n",
    "\n",
    "# Example (uncomment to run):\n",
    "# _ = sweep_regularization(kind='ridge', degree=12)\n",
    "# _ = sweep_regularization(kind='lasso', degree=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f86b2",
   "metadata": {},
   "source": [
    "## 9) Conclusions\n",
    "- Discuss where validation error is minimized vs. train/test.\n",
    "- Explain bias (underfitting at low degrees) vs variance (overfitting at high degrees).\n",
    "- Reflect on the effect of regularization (if used).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}